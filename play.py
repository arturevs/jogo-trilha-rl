import time
import torch
import numpy as np
import os
import sys

# Ajuste de path para importar mÃ³dulos
sys.path.append(os.getcwd())

from envs.game_logic import TrilhaGame
from envs.trilha_gym import TrilhaEnv
from train import RandomAgent, TrainedModelAgent, DEVICE

# --- CONFIGURAÃ‡ÃƒO VISUAL ---
COLOR_V = "ğŸ”´"  # Jogador V (Vermelho)
COLOR_R = "ğŸ”µ"  # Jogador R (Azul)
COLOR_EMPTY = "âš«"  # Vazio (ou use "âšª" ou "  ")
COLOR_LINE = "â–"
COLOR_PIPE = "â”‚"


def clear_screen():
    os.system("cls" if os.name == "nt" else "clear")


def print_header():
    print("=" * 40)
    print("   TRILHA RL - ARENA DE BATALHA   ")
    print("=" * 40)


def render_board(game):
    """
    Renderiza o tabuleiro de forma bonita no terminal usando a matriz 7x7.
    O jogo usa Ã­ndices lineares (0-23), entÃ£o precisamos mapear.
    """
    # Mapeamento visual reverso (Coord visual -> Ãndice LÃ³gico)
    # Apenas para desenhar. Se for None, Ã© espaÃ§o vazio nÃ£o jogÃ¡vel.

    # Criamos uma matriz 7x7 visual
    grid = [[None for _ in range(7)] for _ in range(7)]

    # Mapeamento do envs/trilha_gym.py (idx_to_coord)
    idx_map = {
        0: (0, 0),
        1: (0, 3),
        2: (0, 6),
        3: (1, 1),
        4: (1, 3),
        5: (1, 5),  # Corrigindo ordem visual concÃªntrica
        # Ops, a lÃ³gica do jogo Ã© Anel Externo -> MÃ©dio -> Interno.
        # Vamos usar o board state direto.
    }

    # Vamos usar o board direto e colocar nas posiÃ§Ãµes manuais para ficar bonito
    b = game.board

    def p(idx):
        piece = b[idx]
        if piece == "V":
            return COLOR_V
        if piece == "R":
            return COLOR_R
        return "âšª"  # Ponto vazio jogÃ¡vel

    # Layout ASCII Hardcoded para Trilha
    # Indices baseados no game_logic.py:
    # Ext: 0..7 | Med: 8..15 | Int: 16..23

    print(f"\n   {p(0)}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€{p(1)}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€{p(2)}")
    print("   â”‚              â”‚              â”‚")
    print(f"   â”‚      {p(8)}â”€â”€â”€â”€â”€â”€â”€{p(9)}â”€â”€â”€â”€â”€â”€â”€{p(10)}      â”‚")
    print("   â”‚      â”‚       â”‚       â”‚      â”‚")
    print(f"   â”‚      â”‚   {p(16)}â”€â”€â”€{p(17)}â”€â”€â”€{p(18)}   â”‚      â”‚")
    print("   â”‚      â”‚   â”‚       â”‚   â”‚      â”‚")
    print(f"   {p(7)}â”€â”€â”€â”€â”€â”€{p(15)}â”€â”€â”€{p(23)}       {p(19)}â”€â”€â”€{p(11)}â”€â”€â”€â”€â”€â”€{p(3)}")
    print("   â”‚      â”‚   â”‚       â”‚   â”‚      â”‚")
    print(f"   â”‚      â”‚   {p(22)}â”€â”€â”€{p(21)}â”€â”€â”€{p(20)}   â”‚      â”‚")
    print("   â”‚      â”‚       â”‚       â”‚      â”‚")
    print(f"   â”‚      {p(14)}â”€â”€â”€â”€â”€â”€â”€{p(13)}â”€â”€â”€â”€â”€â”€â”€{p(12)}      â”‚")
    print("   â”‚              â”‚              â”‚")
    print(f"   {p(6)}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€{p(5)}â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€{p(4)}\n")

    # Placar
    print(f"   Turno: {COLOR_V if game.turn == 'V' else COLOR_R}")
    print(f"   Fase: {game.phase}")
    if game.pending_removal:
        print("   âš ï¸  TRILHA FORMADA! REMOVENDO PEÃ‡A... âš ï¸")
    print(
        f"   PeÃ§as {COLOR_V}: {game.pieces_on_board['V']} (MÃ£o: {game.pieces_to_place['V']})"
    )
    print(
        f"   PeÃ§as {COLOR_R}: {game.pieces_on_board['R']} (MÃ£o: {game.pieces_to_place['R']})"
    )
    print("-" * 40)


def get_agent_choice(player_name):
    print(f"\nEscolha o Agente para o Jogador {player_name}:")
    print("1. ğŸ² AleatÃ³rio (Random)")
    print("2. ğŸ§  Modelo Fase 1 (Vs Random)")
    print("3. ğŸ† Modelo Fase 2 (Vs Expert)")

    while True:
        try:
            choice = input("OpÃ§Ã£o (1-3): ")
            if choice == "1":
                return "RANDOM", None
            if choice == "2":
                return "MODEL", "model_vs_random.pth"
            if choice == "3":
                return "MODEL", "model_vs_expert.pth"
        except KeyboardInterrupt:
            sys.exit()


def create_agent(type, path, env):
    if type == "RANDOM":
        return RandomAgent()
    elif type == "MODEL":
        if not os.path.exists(path):
            print(f"âŒ Erro: Modelo '{path}' nÃ£o encontrado! Treine primeiro.")
            sys.exit()
        print(f"Carregando {path}...")
        return TrainedModelAgent(path, env)


def run_match(agent_v, agent_r, delay=0.5):
    env = TrilhaEnv()
    obs, info = env.reset()
    game = env.game

    # Mapear agentes
    agents = {"V": agent_v, "R": agent_r}

    done = False

    while not done:
        clear_screen()
        print_header()
        render_board(game)

        current_player = game.turn
        current_agent = agents[current_player]

        # Pega aÃ§Ã£o
        # Nota: TrainedModelAgent precisa do mask e state
        mask = env.get_action_mask()

        # Pequeno delay para visualizaÃ§Ã£o
        time.sleep(delay)

        print(f"ğŸ¤” {current_player} estÃ¡ pensando...")

        # O TrainedModelAgent foi feito para jogar como "V" (Player 1 da visÃ£o da rede).
        # Se ele estiver jogando como "R", precisamos inverter a observaÃ§Ã£o?
        # A classe TrilhaEnv atual jÃ¡ inverte a observaÃ§Ã£o no _get_obs() baseada no turno!
        # EntÃ£o o obs[0] Ã© sempre "minhas peÃ§as" e obs[1] "inimigo".
        # O modelo pode jogar de qualquer lado sem mexer nos dados.

        action = current_agent.act(obs, mask, game)

        # Executa no ambiente
        # Importante: Como estamos rodando manualmente o loop, usamos game.apply direto?
        # NÃ£o, usamos env.step para manter compatibilidade com a lÃ³gica de recompensa/regra
        # Mas o env.step atual executa DOIS turnos (Agente e Oponente).
        # Precisamos de um step "unitÃ¡rio" para visualizaÃ§Ã£o passo a passo.
        # Vamos interagir direto com a lÃ³gica do jogo (game) ou adaptar o env.

        # Para visualizaÃ§Ã£o, Ã© melhor chamar a lÃ³gica do jogo diretamente com proteÃ§Ãµes,
        # pois o env.step foi desenhado para treino (turnos acoplados).

        try:
            if action < 24:
                game.apply_place(action)
            else:
                # Decodificar movimento
                move_idx = action - 24
                start = move_idx // 4
                direction = move_idx % 4
                dirs = ["d", "e", "c", "b"]
                target = game.ADJACENCY[start][dirs[direction]]
                game.apply_move(start, target)

            # Auto-remoÃ§Ã£o visual
            if game.pending_removal:
                clear_screen()
                print_header()
                render_board(game)
                print(f"âš”ï¸  {current_player} fez trilha! Removendo peÃ§a...")
                time.sleep(delay)

                # Tenta remover (LÃ³gica simplificada igual ao treino: primeira vÃ¡lida)
                removed = False
                opp = "R" if current_player == "V" else "V"
                for i, p in enumerate(game.board):
                    if p == opp:
                        try:
                            game.apply_remove(i)
                            removed = True
                            break
                        except:
                            continue

                if not removed:
                    # Caso raro onde nÃ£o dÃ¡ pra remover nada (nÃ£o deveria acontecer mais)
                    game.pending_removal = False
                    game._switch_turn_logic()

        except Exception as e:
            print(f"âŒ Erro CrÃ­tico: {e}")
            break

        # Verifica vitÃ³ria
        winner = game.check_winner()
        if winner:
            clear_screen()
            print_header()
            render_board(game)
            print(
                f"\nğŸ‰ğŸ‰ VITORIA DO JOGADOR {COLOR_V if winner == 'V' else COLOR_R} ({winner})! ğŸ‰ğŸ‰"
            )
            break

        # Atualiza obs para o prÃ³ximo
        obs = env._get_obs()


def main():
    clear_screen()
    print_header()

    # Setup Env dummy para carregar modelos (pegar shapes)
    dummy_env = TrilhaEnv()

    print("ConfiguraÃ§Ã£o da Partida:")
    type_v, path_v = get_agent_choice(f"{COLOR_V} (Vermelho/Primeiro)")
    type_r, path_r = get_agent_choice(f"{COLOR_R} (Azul/Segundo)")

    agent_v = create_agent(type_v, path_v, dummy_env)
    agent_r = create_agent(type_r, path_r, dummy_env)

    print("\nIniciando partida em 3 segundos...")
    time.sleep(3)

    run_match(agent_v, agent_r, delay=0.5)


if __name__ == "__main__":
    main()
